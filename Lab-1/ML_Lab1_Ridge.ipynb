{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:04:45.383430Z",
     "start_time": "2025-11-11T14:04:45.381054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error"
   ],
   "id": "ee55f017143df1a9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "08610485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:04:46.644455Z",
     "start_time": "2025-11-11T14:04:46.613151Z"
    }
   },
   "source": [
    "DATA_PATH = \"train.csv\"\n",
    "df = pd.read_csv(DATA_PATH)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "832b5474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T14:04:48.632417Z",
     "start_time": "2025-11-11T14:04:48.377571Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TOP_K = 8\n",
    "DEGREE = 4\n",
    "ALPHA = 1.1\n",
    "ABS_CLIP_OUTLIERS = 1000\n",
    "\n",
    "df = df.loc[df[\"RiskScore\"].abs() <= ABS_CLIP_OUTLIERS].copy()\n",
    "\n",
    "X = df.copy()\n",
    "\n",
    "categorial_feature = ['MaritalStatus', 'HomeOwnershipStatus', 'LoanPurpose', 'EmploymentStatus', 'EducationLevel']\n",
    "X_num = X.select_dtypes(include=[np.number]).drop(columns=[\"RiskScore\"], errors=\"ignore\")\n",
    "X_categorial = X[categorial_feature].copy()\n",
    "y = X[\"RiskScore\"].astype(float).values\n",
    "\n",
    "quantile_min = X_num.quantile(0.01)\n",
    "quantile_max = X_num.quantile(0.99)\n",
    "X_wins = X_num.clip(lower=quantile_min, upper=quantile_max, axis=1)\n",
    "\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_imp = pd.DataFrame(imp.fit_transform(X_wins), columns=X_wins.columns)\n",
    "\n",
    "\n",
    "def split_date(df):\n",
    "    s = pd.to_datetime(df['ApplicationDate'], errors='coerce')\n",
    "    return pd.DataFrame({\n",
    "        'year': s.dt.year,\n",
    "        'quarter': s.dt.quarter,\n",
    "        'month': s.dt.month,\n",
    "        'dow': s.dt.dayofweek\n",
    "    }, index=df.index)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imp), columns=X_imp.columns)\n",
    "\n",
    "corr = X_scaled.assign(RiskScore=y).corr()[\"RiskScore\"].drop(\"RiskScore\").abs().sort_values(ascending=False)\n",
    "top_numeric = corr.head(TOP_K).index.tolist()\n",
    "other_columns = [c for c in X_scaled.columns if c not in top_numeric]\n",
    "\n",
    "poly = PolynomialFeatures(degree=DEGREE)\n",
    "X_poly = pd.DataFrame(poly.fit_transform(X_scaled[top_numeric]), columns=poly.get_feature_names_out(top_numeric))\n",
    "\n",
    "dates = split_date(df)\n",
    "\n",
    "X_cat_dummies = pd.get_dummies(X_categorial, drop_first=True)\n",
    "X_final = pd.concat(\n",
    "    [X_scaled[other_columns].reset_index(drop=True),\n",
    "     X_poly.reset_index(drop=True),\n",
    "     X_cat_dummies.reset_index(drop=True),\n",
    "     dates.reset_index(drop=True)],\n",
    "    axis=1)\n",
    "print(f\"Frame: {X_final.shape[1]} features (other columns: {len(other_columns)}, polynomial on {TOP_K} cols, {DEGREE} degree)\")\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_final, y, train_size=0.8)\n",
    "ridge = Ridge(alpha=ALPHA, random_state=42)\n",
    "ridge.fit(X_train, y_train)\n",
    "test_pred = ridge.predict(X_train.copy())\n",
    "validation_pred = ridge.predict(X_validation.copy())\n",
    "\n",
    "\n",
    "train_mse = mean_squared_error(y_train, test_pred)\n",
    "train_rmse = train_mse ** 0.5\n",
    "train_r2 = r2_score(y_train, test_pred)\n",
    "train_mae = mean_absolute_error(y_train, test_pred)\n",
    "train_mape = mean_absolute_percentage_error(y_train, test_pred)\n",
    "validation_mse = mean_squared_error(y_validation, validation_pred)\n",
    "validation_rmse = validation_mse ** 0.5\n",
    "validation_r2 = r2_score(y_validation, validation_pred)\n",
    "validation_mae = mean_absolute_error(y_validation, validation_pred)\n",
    "validation_mape = mean_absolute_percentage_error(y_validation, validation_pred)\n",
    "\n",
    "print(f\"TRAIN MSE: {train_mse:.4f} | RMSE: {train_rmse:.4f} | R^2: {train_r2:.4f} | MAE: {train_mae:.4f} | MAPE: {train_mape:.4f}\")\n",
    "print(f\"VALIDATION MSE: {validation_mse:.4f} | RMSE: {validation_rmse:.4f} | R^2: {validation_r2:.4f} | MAE: {validation_mae:.4f} | MAPE: {validation_mape:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design matrix: 535 features (base rest: 20, poly on 8 cols, degree 4)\n",
      "TRAIN MSE: 22.6472 | RMSE: 4.7589 | R^2: 0.9237 | MAE: 3.5150 | MAPE: 0.0815\n",
      "VALIDATION MSE: 29.4024 | RMSE: 5.4224 | R^2: 0.9011 | MAE: 3.7732 | MAPE: 0.0866\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T19:30:11.669709Z",
     "start_time": "2025-11-04T19:30:11.662080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "def split_date(df):\n",
    "    s = pd.to_datetime(df['ApplicationDate'], errors='coerce')\n",
    "    return pd.DataFrame({\n",
    "        'year': s.dt.year,\n",
    "        'quarter': s.dt.quarter,\n",
    "        'month': s.dt.month,\n",
    "        'dow': s.dt.dayofweek\n",
    "    }, index=df.index)\n",
    "\n",
    "\n",
    "categorial_feature = ['MaritalStatus', 'HomeOwnershipStatus', 'LoanPurpose', 'EmploymentStatus', 'EducationLevel']\n",
    "\n",
    "\n",
    "def fit_model(train_path, abs_clip_outliers, top_k, degree, alpha) -> dict[str, Any]:\n",
    "    df = pd.read_csv(train_path).copy()\n",
    "\n",
    "    df = df[~df[\"RiskScore\"].isna()].copy()\n",
    "    df = df[df[\"RiskScore\"].abs() <= abs_clip_outliers].copy()\n",
    "\n",
    "    X_num = df.select_dtypes(include=[np.number]).drop(columns=[\"RiskScore\"], errors=\"ignore\")\n",
    "    X_categorial = df[categorial_feature].copy()\n",
    "    y = df[\"RiskScore\"].astype(float).values\n",
    "\n",
    "    quantile_min = X_num.quantile(0.01)\n",
    "    quantile_max = X_num.quantile(0.99)\n",
    "    X_wins = X_num.clip(lower=quantile_min, upper=quantile_max, axis=1)\n",
    "\n",
    "    imp = SimpleImputer(strategy=\"median\").fit(X_wins)\n",
    "    X_imp = pd.DataFrame(imp.transform(X_wins), columns=X_wins.columns)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_imp)\n",
    "    X_scaled = pd.DataFrame(scaler.transform(X_imp), columns=X_imp.columns)\n",
    "\n",
    "    corr = X_scaled.assign(RiskScore=y).corr()[\"RiskScore\"].drop(\"RiskScore\").abs().sort_values(ascending=False)\n",
    "    top_numeric = corr.head(top_k).index.tolist()\n",
    "    other_columns = [c for c in X_scaled.columns if c not in top_numeric]\n",
    "\n",
    "    poly = PolynomialFeatures(degree=degree).fit(X_scaled[top_numeric])\n",
    "    X_poly = pd.DataFrame(poly.transform(X_scaled[top_numeric]),\n",
    "                          columns=poly.get_feature_names_out(top_numeric))\n",
    "\n",
    "    dates = split_date(df)\n",
    "    X_cat_dummies = pd.get_dummies(X_categorial, drop_first=True)\n",
    "    X_final = pd.concat([\n",
    "        X_scaled[other_columns].reset_index(drop=True),\n",
    "        X_poly.reset_index(drop=True),\n",
    "        X_cat_dummies.reset_index(drop=True),\n",
    "        dates.reset_index(drop=True)],\n",
    "        axis=1)\n",
    "    model = Ridge(alpha=alpha, random_state=42).fit(X_final, y)\n",
    "\n",
    "    model_fit_data = {\n",
    "        \"numeric_columns\": X_num.columns.tolist(), \"other_columns\": other_columns, \"top_numeric\": top_numeric,\n",
    "        \"quantile_min\": quantile_min, \"quantile_max\": quantile_max, \"scaler\": scaler, \"imputer\": imp, \"poly\": poly,\n",
    "        \"model\": model\n",
    "    }\n",
    "    return model_fit_data"
   ],
   "id": "77449abd3da50f0c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T19:30:14.352307Z",
     "start_time": "2025-11-04T19:30:14.347079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_data(test_path, model_fit_data, out_path=\"predictions.csv\"):\n",
    "    df = pd.read_csv(test_path).copy()\n",
    "\n",
    "    X_num = df.reindex(columns=model_fit_data[\"numeric_columns\"])\n",
    "    X_categorial = df[categorial_feature].copy()\n",
    "    X_wins = X_num.clip(lower=model_fit_data[\"quantile_min\"], upper=model_fit_data[\"quantile_max\"], axis=1)\n",
    "    X_imputer = pd.DataFrame(model_fit_data[\"imputer\"].transform(X_wins), columns=model_fit_data[\"numeric_columns\"])\n",
    "    X_scaled = pd.DataFrame(model_fit_data[\"scaler\"].transform(X_imputer), columns=model_fit_data[\"numeric_columns\"])\n",
    "\n",
    "    other_columns = model_fit_data[\"other_columns\"]\n",
    "    top_numeric = model_fit_data[\"top_numeric\"]\n",
    "    X_poly = pd.DataFrame(\n",
    "        model_fit_data[\"poly\"].transform(X_scaled[top_numeric]),\n",
    "        columns=model_fit_data[\"poly\"].get_feature_names_out(top_numeric)\n",
    "    )\n",
    "\n",
    "    dates = split_date(df)\n",
    "    X_cat_dummies = pd.get_dummies(X_categorial, drop_first=True)\n",
    "    X_final = pd.concat([X_scaled[other_columns].reset_index(drop=True), X_poly.reset_index(drop=True),\n",
    "                         X_cat_dummies.reset_index(drop=True), dates.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    prediction = model_fit_data[\"model\"].predict(X_final)\n",
    "\n",
    "    output = pd.DataFrame({\"prediction\": prediction})\n",
    "    output.insert(0, \"ID\", df[\"ID\"].values)\n",
    "    output.to_csv(out_path, index=False)\n",
    "    return output"
   ],
   "id": "fdc4e9f860ed7ec8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T19:30:16.946784Z",
     "start_time": "2025-11-04T19:30:16.583950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_fit_data = fit_model(\"train.csv\", abs_clip_outliers=ABS_CLIP_OUTLIERS, top_k=8, degree=4, alpha=5.0)\n",
    "sub = predict_data(\"test.csv\", model_fit_data, out_path=\"predictions.csv\")\n",
    "print(sub.head())\n"
   ],
   "id": "aaa3e43f9936fa8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  prediction\n",
      "0   0   33.176446\n",
      "1   1   53.104048\n",
      "2   2   29.658294\n",
      "3   3   35.943292\n",
      "4   4   33.248941\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
